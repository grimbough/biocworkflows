{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-   [Using Bioconductor for High Throughput\n",
    "    Assays](#using-bioconductor-for-high-throughput-assays)\n",
    "    -   [Flow Cytometry](#flow-cytometry)\n",
    "    -   [Cell-based Assays](#cell-based-assays)\n",
    "    -   [High-throughput qPCR Assays](#high-throughput-qpcr-assays)\n",
    "    -   [Mass Spectrometry and Proteomics\n",
    "        data](#mass-spectrometry-and-proteomics-data)\n",
    "    -   [Imaging Based Assays](#imaging-based-assays)\n",
    "\n",
    "Using Bioconductor for High Throughput Assays\n",
    "=============================================\n",
    "\n",
    "Bioconductor includes packages for analysis of diverse areas of high-throughput assays such as flow cytometry, quantitative real-time PCR, mass spectrometry, proteomics and other cell-based data.\n",
    "\n",
    "-   [Sample Workflow](#sample-workflow)\n",
    "-   [Installation and Use](#install-and-use)\n",
    "-   [Exploring Package Content](#exploring-package-content)\n",
    "-   [Diverse Assays Resources](#diverse-assays-resources)\n",
    "\n",
    "<h2 id=\"sample-workflow\">\n",
    "Sample Workflow\n",
    "</h2>\n",
    "The following psuedo-code illustrates a typical R / Bioconductor session. It makes use of the flow cytometry packages to load, transform and visualize the flow data and gate certain populations in the dataset.\n",
    "\n",
    "The workflow loads the `flowCore`, `flowStats` and `flowViz` packages and its dependencies. It loads the ITN data with 15 samples, each of which includes, in addition to FSC and SSC, 5 fluorescence channels: CD3, CD4, CD8, CD69 and HLADR."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading required package: fda\n",
      "Loading required package: splines\n",
      "Loading required package: Matrix\n",
      "\n",
      "Attaching package: ‘Matrix’\n",
      "\n",
      "The following object is masked from ‘package:flowCore’:\n",
      "\n",
      "    %&%\n",
      "\n",
      "\n",
      "Attaching package: ‘fda’\n",
      "\n",
      "The following object is masked from ‘package:graphics’:\n",
      "\n",
      "    matplot\n",
      "\n",
      "Loading required package: mvoutlier\n",
      "Loading required package: sgeostat\n",
      "sROC 0.1-2 loaded\n",
      "Loading required package: cluster\n",
      "Loading required package: flowWorkspace\n",
      "Loading required package: flowViz\n",
      "Loading required package: lattice\n",
      "Loading required package: ncdfFlow\n",
      "Loading required package: RcppArmadillo\n",
      "Loading required package: BH\n",
      "Loading required package: gridExtra\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "A flowSet with 15 experiments.\n",
       "\n",
       "An object of class 'AnnotatedDataFrame'\n",
       "  rowNames: sample01 sample02 ... sample15 (15 total)\n",
       "  varLabels: GroupID SiteCode ... name (7 total)\n",
       "  varMetadata: labelDescription\n",
       "\n",
       "  column names:\n",
       "  FSC SSC CD8 CD69 CD4 CD3 HLADr Time"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Load packages\n",
    "library(flowCore)\n",
    "library(flowStats)\n",
    "library(flowViz) # for flow data visualization\n",
    "\n",
    "## Load data\n",
    "data(ITN)\n",
    "ITN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we need to transform all the fluorescence channels. Using a `workFlow` object can help to keep track of our progress."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message:\n",
      ": 'workFlow' is deprecated.\n",
      "Use 'flowWorkspace::GatingSet' instead.\n",
      "See help(\"Deprecated\")"
     ]
    }
   ],
   "source": [
    "## Create a workflow instance and transform data using asinh\n",
    "wf <- workFlow(ITN)\n",
    "asinh <- arcsinhTransform()\n",
    "tl <- transformList(colnames(ITN)[3:7], asinh, \n",
    "                      transformationId = \"asinh\")\n",
    "add(wf, tl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we use the `lymphGate` function to find the T-cells in the CD3/SSC projection."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "``` r\n",
    "lg <- lymphGate(Data(wf[[\"asinh\"]]), channels=c(\"SSC\", \"CD3\"),\n",
    "         preselection=\"CD4\", filterId=\"TCells\", eval=FALSE,\n",
    "         scale=2.5)\n",
    "add(wf, lg$n2gate, parent=\"asinh\")\n",
    "print(xyplot(SSC ~ CD3| PatientID, wf[[\"TCells+\"]],\n",
    "             par.settings=list(gate=list(col=\"red\", \n",
    "             fill=\"red\", alpha=0.3))))\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A typical workflow for flow cytometry data analysis in Bioconductor flow packages include data transformation, normalization, filtering, manual gating, semi-automatic gating and automatic clustering if desired. Details can be found in [flowWorkFlow.pdf](flowWorkFlow.pdf) or the vignettes of the [flow cytometry packages](#diverse-assays-resources).\n",
    "\n",
    "<p class=\"back_to_top\">\n",
    "\\[ <a href=\"#top\">Back to top</a> \\]\n",
    "</p>\n",
    "<h2 id=\"install-and-use\">\n",
    "Installation and Use\n",
    "</h2>\n",
    "Follow [installation instructions](/install/) to start using these packages. To install the `flowCore` package and all of its dependencies, evaluate the commands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Bioconductor version 3.2 (BiocInstaller 1.20.1), ?biocLite for help\n",
      "BioC_mirror: https://bioconductor.org\n",
      "Using Bioconductor 3.2 (BiocInstaller 1.20.1), R 3.2.2 (2015-08-14).\n",
      "Installing package(s) ‘flowCore’\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The downloaded source packages are in\n",
      "\t‘/tmp/RtmpEm3t8d/downloaded_packages’\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Updating HTML index of packages in '.Library'\n",
      "Making 'packages.html' ... done\n"
     ]
    }
   ],
   "source": [
    "## try http:// if https:// URLs are not supported\n",
    "source(\"https://bioconductor.org/biocLite.R\")\n",
    "biocLite(\"flowCore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Package installation is required only once per R installation. View a full list of [available packages](/packages/release/bioc/).\n",
    "\n",
    "To use the `flowCore` package, evaluate the command"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "library(\"flowCore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This instruction is required once in each R session.\n",
    "\n",
    "<p class=\"back_to_top\">\n",
    "\\[ <a href=\"#top\">Back to top</a> \\]\n",
    "</p>\n",
    "<h2 id=\"exploring-package-content\">\n",
    "Exploring Package Content\n",
    "</h2>\n",
    "Packages have extensive help pages, and include vignettes highlighting common use cases. The help pages and vignettes are available from within R. After loading a package, use syntax like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<table width=\"100%\" summary=\"page for read.FCS {flowCore}\"><tr><td>read.FCS {flowCore}</td><td style=\"text-align: right;\">R Documentation</td></tr></table>\n",
       "\n",
       "<h2>Read an FCS file</h2>\n",
       "\n",
       "<h3>Description</h3>\n",
       "\n",
       "<p>Check validity and Read Data File Standard for Flow Cytometry</p>\n",
       "\n",
       "\n",
       "<h3>Usage</h3>\n",
       "\n",
       "<pre>\n",
       "\n",
       "   isFCSfile(files)\n",
       "\n",
       "   read.FCS(filename, transformation=\"linearize\", which.lines=NULL,\n",
       "            alter.names=FALSE, column.pattern=NULL, invert.pattern = FALSE,\n",
       "            decades=0, ncdf = FALSE, min.limit=NULL, truncate_max_range = TRUE, dataset=NULL, emptyValue=TRUE, ...)\n",
       "\n",
       "</pre>\n",
       "\n",
       "\n",
       "<h3>Arguments</h3>\n",
       "\n",
       "<table summary=\"R argblock\">\n",
       "<tr valign=\"top\"><td><code>files</code></td>\n",
       "<td>\n",
       "<p> A vector of filenames </p>\n",
       "</td></tr>\n",
       "<tr valign=\"top\"><td><code>filename</code></td>\n",
       "<td>\n",
       "<p>Character of length 1: filename</p>\n",
       "</td></tr>\n",
       "<tr valign=\"top\"><td><code>transformation</code></td>\n",
       "<td>\n",
       "<p>An character string that defines the type of\n",
       "transformation. Valid values are <code>linearize</code> (default),\n",
       "<code>linearize-with-PnG-scaling</code>, or <code>scale</code>.\n",
       "The <code>linearize</code> transformation applies the\n",
       "appropriate power transform to the data. The\n",
       "<code>linearize-with-PnG-scaling</code> transformation applies the\n",
       "appropriate power transform for parameters stored on log scale, and\n",
       "also a linear scaling transformation based on the 'gain' (FCS \\$PnG keywords)\n",
       "for parameters stored on a linear scale. The <code>scale</code>\n",
       "transformation scales all columns to $[0,10^decades]$.  defaulting\n",
       "to decades=0 as in the FCS4 specification. \n",
       "A logical can also be used: <code>TRUE</code> is equal to <code>linearize</code> and <code>FALSE</code>(or <code>NULL</code>)\n",
       "corresponds to no transformation.\n",
       "Also when the transformation keyword of the FCS header is set to &quot;custom&quot; or &quot;applied&quot;, no transformation will be used.\n",
       "</p>\n",
       "</td></tr>\n",
       "<tr valign=\"top\"><td><code>which.lines</code></td>\n",
       "<td>\n",
       "<p>Numeric vector to specify the indices of the lines\n",
       "to be read. If NULL all the records are read, if of length 1, a\n",
       "random sample of the size indicated by <code>which.lines</code> is read\n",
       "in.</p>\n",
       "</td></tr>\n",
       "<tr valign=\"top\"><td><code>alter.names</code></td>\n",
       "<td>\n",
       "<p>boolean indicating whether or not we should rename\n",
       "the columns to valid R names using <code>make.names</code>. The\n",
       "default is FALSE.</p>\n",
       "</td></tr>\n",
       "<tr valign=\"top\"><td><code>column.pattern</code></td>\n",
       "<td>\n",
       "<p>An optional regular expression defining\n",
       "parameters we should keep when loading the file. The default is\n",
       "NULL. </p>\n",
       "</td></tr>\n",
       "<tr valign=\"top\"><td><code>invert.pattern</code></td>\n",
       "<td>\n",
       "<p>logical. By default, <code>FALSE</code>. If <code>TRUE</code>,\n",
       "inverts the regular expression specified in <code>column.pattern</code>. This is\n",
       "useful for indicating the channel names that we do not want to read. If\n",
       "<code>column.pattern</code> is set to <code>NULL</code>, this argument is ignored.</p>\n",
       "</td></tr>\n",
       "<tr valign=\"top\"><td><code>decades</code></td>\n",
       "<td>\n",
       "<p>When scaling is activated, the number of decades to use\n",
       "for the output.</p>\n",
       "</td></tr>\n",
       "<tr valign=\"top\"><td><code>ncdf</code></td>\n",
       "<td>\n",
       "<p>Deprecated. Please use 'ncdfFlow' package for cdf based storage.</p>\n",
       "</td></tr>\n",
       "<tr valign=\"top\"><td><code>min.limit</code></td>\n",
       "<td>\n",
       "<p>The minimum value in the data range that is\n",
       "allowed. Some instruments produce extreme artifactual values. The\n",
       "positive data range for each parameter is completely defined by the\n",
       "measurement range of the instrument and all larger values are set to\n",
       "this threshold. The lower data boundary is not that well defined,\n",
       "since compensation might shift some values below the original\n",
       "measurement range of the instrument. The default value of <code>-111</code>\n",
       "copies the behavior of flowJo. It can be set to an arbitrary number\n",
       "or to <code>NULL</code>, in which case the original values are kept. </p>\n",
       "</td></tr>\n",
       "<tr valign=\"top\"><td><code>truncate_max_range</code></td>\n",
       "<td>\n",
       "<p>logical type. Default is TRUE. can be optionally turned off\n",
       "to avoid truncating the extreme positive value to the instrument measurement range .i.e.'$PnR'.\n",
       "</p>\n",
       "</td></tr>\n",
       "<tr valign=\"top\"><td><code>dataset</code></td>\n",
       "<td>\n",
       "<p>The FCS file specification allows for multiple data\n",
       "segments in a single file. Since the output of <code>read.FCS</code> is a\n",
       "single <code>flowFrame</code> we can't automatically read in all available\n",
       "sets. This parameter allows to chose one of the subsets for\n",
       "import. Its value is supposed to be an integer in the range of\n",
       "available data sets. This argument is ignored if there is only a\n",
       "single data segment in the FCS file.</p>\n",
       "</td></tr>\n",
       "<tr valign=\"top\"><td><code>emptyValue</code></td>\n",
       "<td>\n",
       "<p>boolean indicating whether or not we allow empty value for keyword values in TEXT segment.\n",
       "It affects how the double delimiters are treated.\n",
       "IF TRUE, The double delimiters are parsed as a pair of start and end single delimiter for an empty value.\n",
       "Otherwise, double delimiters are parsed one part of string as the keyword value.\n",
       "default is TRUE.</p>\n",
       "</td></tr>\n",
       "<tr valign=\"top\"><td><code>...</code></td>\n",
       "<td>\n",
       "<p>other arguments. </p>\n",
       "</td></tr>\t\t\n",
       "</table>\n",
       "\n",
       "\n",
       "<h3>Details</h3>\n",
       "\n",
       "<p>The function <code>isFCSfile</code> determines whether its arguments are\n",
       "valid FCS files.\n",
       "</p>\n",
       "<p>The function <code>read.FCS</code> works with the output of the FACS machine\n",
       "software from a number of vendors (FCS 2.0, FCS 3.0 and List Mode Data\n",
       "LMD). However, the FCS 3.0 standard includes some options that are not\n",
       "yet implemented in this function. If you need extensions, please let\n",
       "me know. The output of the function is an object of class\n",
       "<code>flowFrame</code>.\n",
       "</p>\n",
       "<p>For specifications of FCS 3.0 see <a href=\"http://www.isac-net.org\">http://www.isac-net.org</a> and\n",
       "the file <a href=\"../doc/fcs3.html\">../doc/fcs3.html</a> in the <code>doc</code> directory of the\n",
       "package.\n",
       "</p>\n",
       "<p>The <code>which.lines</code> arguments allow you to read a subset of the record as you might not want to read the thousands of\n",
       "events recorded in the FCS file.  It is mainly used when there is not enough memory to read one single FCS (which probably will not happen).\n",
       "It will probably take more time than reading the entire FCS (due to the multiple disk IO).\n",
       "</p>\n",
       "\n",
       "\n",
       "<h3>Value</h3>\n",
       "\n",
       "<p><code>isFCSfile</code> returns a logical vector.\n",
       "</p>\n",
       "<p><code>read.FCS</code> returns an object of class\n",
       "<code>flowFrame</code> that contains the\n",
       "data in the <code>exprs</code> slot, the parameters monitored in the\n",
       "<code>parameters</code> slot and the keywords and value saved in the header\n",
       "of the FCS file. \n",
       "</p>\n",
       "\n",
       "\n",
       "<h3>Author(s)</h3>\n",
       "\n",
       "<p>F. Hahne, N.Le Meur</p>\n",
       "\n",
       "\n",
       "<h3>See Also</h3>\n",
       "\n",
       "<p><code>read.flowSet</code></p>\n",
       "\n",
       "\n",
       "<h3>Examples</h3>\n",
       "\n",
       "<pre>\n",
       "## a sample file\n",
       "fcsFile &lt;- system.file(\"extdata\", \"0877408774.B08\", package=\"flowCore\")\n",
       "\n",
       "## read file and linearize values\n",
       "samp &lt;-  read.FCS(fcsFile, transformation=\"linearize\")\n",
       "exprs(samp[1:3,])\n",
       "description(samp)[3:6]\n",
       "class(samp)\n",
       "\n",
       "## Only read in lines 2 to 5\n",
       "subset &lt;- read.FCS(fcsFile, which.lines=2:5, transformation=\"linearize\")\n",
       "exprs(subset)\n",
       "\n",
       "## Read in a random sample of 100 lines\n",
       "subset &lt;- read.FCS(fcsFile, which.lines=100, transformation=\"linearize\")\n",
       "nrow(subset)\n",
       "\n",
       "</pre>\n",
       "\n",
       "<hr /><div style=\"text-align: center;\">[Package <em>flowCore</em> version 1.36.3 ]</div>"
      ],
      "text/latex": [
       "\\inputencoding{utf8}\n",
       "\\HeaderA{read.FCS}{Read an FCS file}{read.FCS}\n",
       "\\aliasA{cleanup}{read.FCS}{cleanup}\n",
       "\\aliasA{isFCSfile}{read.FCS}{isFCSfile}\n",
       "\\keyword{IO}{read.FCS}\n",
       "%\n",
       "\\begin{Description}\\relax\n",
       "Check validity and Read Data File Standard for Flow Cytometry\n",
       "\\end{Description}\n",
       "%\n",
       "\\begin{Usage}\n",
       "\\begin{verbatim}\n",
       "\n",
       "   isFCSfile(files)\n",
       "\n",
       "   read.FCS(filename, transformation=\"linearize\", which.lines=NULL,\n",
       "            alter.names=FALSE, column.pattern=NULL, invert.pattern = FALSE,\n",
       "            decades=0, ncdf = FALSE, min.limit=NULL, truncate_max_range = TRUE, dataset=NULL, emptyValue=TRUE, ...)\n",
       "\n",
       "\\end{verbatim}\n",
       "\\end{Usage}\n",
       "%\n",
       "\\begin{Arguments}\n",
       "\\begin{ldescription}\n",
       "\n",
       "\\item[\\code{files}]  A vector of filenames \n",
       "\n",
       "\\item[\\code{filename}] Character of length 1: filename\n",
       "\n",
       "\\item[\\code{transformation}] An character string that defines the type of\n",
       "transformation. Valid values are \\code{linearize} (default),\n",
       "\\code{linearize-with-PnG-scaling}, or \\code{scale}.\n",
       "The \\code{linearize} transformation applies the\n",
       "appropriate power transform to the data. The\n",
       "\\code{linearize-with-PnG-scaling} transformation applies the\n",
       "appropriate power transform for parameters stored on log scale, and\n",
       "also a linear scaling transformation based on the 'gain' (FCS \\bsl{}\\$PnG keywords)\n",
       "for parameters stored on a linear scale. The \\code{scale}\n",
       "transformation scales all columns to \\$[0,10\\textasciicircum{}decades]\\$.  defaulting\n",
       "to decades=0 as in the FCS4 specification. \n",
       "A logical can also be used: \\code{TRUE} is equal to \\code{linearize} and \\code{FALSE}(or \\code{NULL})\n",
       "corresponds to no transformation.\n",
       "Also when the transformation keyword of the FCS header is set to \"custom\" or \"applied\", no transformation will be used.\n",
       "\n",
       "\n",
       "\\item[\\code{which.lines}] Numeric vector to specify the indices of the lines\n",
       "to be read. If NULL all the records are read, if of length 1, a\n",
       "random sample of the size indicated by \\code{which.lines} is read\n",
       "in.\n",
       "\n",
       "\\item[\\code{alter.names}] boolean indicating whether or not we should rename\n",
       "the columns to valid R names using \\code{\\LinkA{make.names}{make.names}}. The\n",
       "default is FALSE.\n",
       "\n",
       "\\item[\\code{column.pattern}] An optional regular expression defining\n",
       "parameters we should keep when loading the file. The default is\n",
       "NULL. \n",
       "\n",
       "\\item[\\code{invert.pattern}] logical. By default, \\code{FALSE}. If \\code{TRUE},\n",
       "inverts the regular expression specified in \\code{column.pattern}. This is\n",
       "useful for indicating the channel names that we do not want to read. If\n",
       "\\code{column.pattern} is set to \\code{NULL}, this argument is ignored.\n",
       "\n",
       "\\item[\\code{decades}] When scaling is activated, the number of decades to use\n",
       "for the output.\n",
       "\n",
       "\\item[\\code{ncdf}] Deprecated. Please use 'ncdfFlow' package for cdf based storage.\n",
       "\n",
       "\\item[\\code{min.limit}] The minimum value in the data range that is\n",
       "allowed. Some instruments produce extreme artifactual values. The\n",
       "positive data range for each parameter is completely defined by the\n",
       "measurement range of the instrument and all larger values are set to\n",
       "this threshold. The lower data boundary is not that well defined,\n",
       "since compensation might shift some values below the original\n",
       "measurement range of the instrument. The default value of \\code{-111}\n",
       "copies the behavior of flowJo. It can be set to an arbitrary number\n",
       "or to \\code{NULL}, in which case the original values are kept. \n",
       "\n",
       "\\item[\\code{truncate\\_max\\_range}] logical type. Default is TRUE. can be optionally turned off\n",
       "to avoid truncating the extreme positive value to the instrument measurement range .i.e.'\\$PnR'.\n",
       "\n",
       "\\item[\\code{dataset}] The FCS file specification allows for multiple data\n",
       "segments in a single file. Since the output of \\code{read.FCS} is a\n",
       "single \\code{flowFrame} we can't automatically read in all available\n",
       "sets. This parameter allows to chose one of the subsets for\n",
       "import. Its value is supposed to be an integer in the range of\n",
       "available data sets. This argument is ignored if there is only a\n",
       "single data segment in the FCS file.\n",
       "\n",
       "\\item[\\code{emptyValue}] boolean indicating whether or not we allow empty value for keyword values in TEXT segment.\n",
       "It affects how the double delimiters are treated.\n",
       "IF TRUE, The double delimiters are parsed as a pair of start and end single delimiter for an empty value.\n",
       "Otherwise, double delimiters are parsed one part of string as the keyword value.\n",
       "default is TRUE.\n",
       "\n",
       "\\item[\\code{...}] other arguments. \t\t\n",
       "\\end{ldescription}\n",
       "\\end{Arguments}\n",
       "%\n",
       "\\begin{Details}\\relax\n",
       "\n",
       "The function \\code{isFCSfile} determines whether its arguments are\n",
       "valid FCS files.\n",
       "\n",
       "The function \\code{read.FCS} works with the output of the FACS machine\n",
       "software from a number of vendors (FCS 2.0, FCS 3.0 and List Mode Data\n",
       "LMD). However, the FCS 3.0 standard includes some options that are not\n",
       "yet implemented in this function. If you need extensions, please let\n",
       "me know. The output of the function is an object of class\n",
       "\\code{flowFrame}.\n",
       "\n",
       "For specifications of FCS 3.0 see \\url{http://www.isac-net.org} and\n",
       "the file \\url{../doc/fcs3.html} in the \\code{doc} directory of the\n",
       "package.\n",
       "\n",
       "The \\code{which.lines} arguments allow you to read a subset of the record as you might not want to read the thousands of\n",
       "events recorded in the FCS file.  It is mainly used when there is not enough memory to read one single FCS (which probably will not happen).\n",
       "It will probably take more time than reading the entire FCS (due to the multiple disk IO).\n",
       "\\end{Details}\n",
       "%\n",
       "\\begin{Value}\n",
       "\n",
       "\\code{isFCSfile} returns a logical vector.\n",
       "\n",
       "\\code{read.FCS} returns an object of class\n",
       "\\code{\\LinkA{flowFrame}{flowFrame}} that contains the\n",
       "data in the \\code{exprs} slot, the parameters monitored in the\n",
       "\\code{parameters} slot and the keywords and value saved in the header\n",
       "of the FCS file. \n",
       "\n",
       "\\end{Value}\n",
       "%\n",
       "\\begin{Author}\\relax\n",
       "F. Hahne, N.Le Meur\n",
       "\\end{Author}\n",
       "%\n",
       "\\begin{SeeAlso}\\relax\n",
       "\\code{\\LinkA{read.flowSet}{read.flowSet}}\n",
       "\\end{SeeAlso}\n",
       "%\n",
       "\\begin{Examples}\n",
       "\\begin{ExampleCode}\n",
       "## a sample file\n",
       "fcsFile <- system.file(\"extdata\", \"0877408774.B08\", package=\"flowCore\")\n",
       "\n",
       "## read file and linearize values\n",
       "samp <-  read.FCS(fcsFile, transformation=\"linearize\")\n",
       "exprs(samp[1:3,])\n",
       "description(samp)[3:6]\n",
       "class(samp)\n",
       "\n",
       "## Only read in lines 2 to 5\n",
       "subset <- read.FCS(fcsFile, which.lines=2:5, transformation=\"linearize\")\n",
       "exprs(subset)\n",
       "\n",
       "## Read in a random sample of 100 lines\n",
       "subset <- read.FCS(fcsFile, which.lines=100, transformation=\"linearize\")\n",
       "nrow(subset)\n",
       "\n",
       "\\end{ExampleCode}\n",
       "\\end{Examples}"
      ],
      "text/plain": [
       "read.FCS               package:flowCore                R Documentation\n",
       "\n",
       "_\bR_\be_\ba_\bd _\ba_\bn _\bF_\bC_\bS _\bf_\bi_\bl_\be\n",
       "\n",
       "_\bD_\be_\bs_\bc_\br_\bi_\bp_\bt_\bi_\bo_\bn:\n",
       "\n",
       "     Check validity and Read Data File Standard for Flow Cytometry\n",
       "\n",
       "_\bU_\bs_\ba_\bg_\be:\n",
       "\n",
       "        isFCSfile(files)\n",
       "     \n",
       "        read.FCS(filename, transformation=\"linearize\", which.lines=NULL,\n",
       "                 alter.names=FALSE, column.pattern=NULL, invert.pattern = FALSE,\n",
       "                 decades=0, ncdf = FALSE, min.limit=NULL, truncate_max_range = TRUE, dataset=NULL, emptyValue=TRUE, ...)\n",
       "     \n",
       "_\bA_\br_\bg_\bu_\bm_\be_\bn_\bt_\bs:\n",
       "\n",
       "   files: A vector of filenames\n",
       "\n",
       "filename: Character of length 1: filename\n",
       "\n",
       "transformation: An character string that defines the type of\n",
       "          transformation. Valid values are ‘linearize’ (default),\n",
       "          ‘linearize-with-PnG-scaling’, or ‘scale’.  The ‘linearize’\n",
       "          transformation applies the appropriate power transform to the\n",
       "          data. The ‘linearize-with-PnG-scaling’ transformation applies\n",
       "          the appropriate power transform for parameters stored on log\n",
       "          scale, and also a linear scaling transformation based on the\n",
       "          'gain' (FCS \\$PnG keywords) for parameters stored on a linear\n",
       "          scale. The ‘scale’ transformation scales all columns to\n",
       "          $[0,10^decades]$.  defaulting to decades=0 as in the FCS4\n",
       "          specification.  A logical can also be used: ‘TRUE’ is equal\n",
       "          to ‘linearize’ and ‘FALSE’(or ‘NULL’) corresponds to no\n",
       "          transformation.  Also when the transformation keyword of the\n",
       "          FCS header is set to \"custom\" or \"applied\", no transformation\n",
       "          will be used.\n",
       "\n",
       "which.lines: Numeric vector to specify the indices of the lines to be\n",
       "          read. If NULL all the records are read, if of length 1, a\n",
       "          random sample of the size indicated by ‘which.lines’ is read\n",
       "          in.\n",
       "\n",
       "alter.names: boolean indicating whether or not we should rename the\n",
       "          columns to valid R names using ‘make.names’. The default is\n",
       "          FALSE.\n",
       "\n",
       "column.pattern: An optional regular expression defining parameters we\n",
       "          should keep when loading the file. The default is NULL.\n",
       "\n",
       "invert.pattern: logical. By default, ‘FALSE’. If ‘TRUE’, inverts the\n",
       "          regular expression specified in ‘column.pattern’. This is\n",
       "          useful for indicating the channel names that we do not want\n",
       "          to read. If ‘column.pattern’ is set to ‘NULL’, this argument\n",
       "          is ignored.\n",
       "\n",
       " decades: When scaling is activated, the number of decades to use for\n",
       "          the output.\n",
       "\n",
       "    ncdf: Deprecated. Please use 'ncdfFlow' package for cdf based\n",
       "          storage.\n",
       "\n",
       "min.limit: The minimum value in the data range that is allowed. Some\n",
       "          instruments produce extreme artifactual values. The positive\n",
       "          data range for each parameter is completely defined by the\n",
       "          measurement range of the instrument and all larger values are\n",
       "          set to this threshold. The lower data boundary is not that\n",
       "          well defined, since compensation might shift some values\n",
       "          below the original measurement range of the instrument. The\n",
       "          default value of ‘-111’ copies the behavior of flowJo. It can\n",
       "          be set to an arbitrary number or to ‘NULL’, in which case the\n",
       "          original values are kept.\n",
       "\n",
       "truncate_max_range: logical type. Default is TRUE. can be optionally\n",
       "          turned off to avoid truncating the extreme positive value to\n",
       "          the instrument measurement range .i.e.'$PnR'.\n",
       "\n",
       " dataset: The FCS file specification allows for multiple data segments\n",
       "          in a single file. Since the output of ‘read.FCS’ is a single\n",
       "          ‘flowFrame’ we can't automatically read in all available\n",
       "          sets. This parameter allows to chose one of the subsets for\n",
       "          import. Its value is supposed to be an integer in the range\n",
       "          of available data sets. This argument is ignored if there is\n",
       "          only a single data segment in the FCS file.\n",
       "\n",
       "emptyValue: boolean indicating whether or not we allow empty value for\n",
       "          keyword values in TEXT segment.  It affects how the double\n",
       "          delimiters are treated.  IF TRUE, The double delimiters are\n",
       "          parsed as a pair of start and end single delimiter for an\n",
       "          empty value.  Otherwise, double delimiters are parsed one\n",
       "          part of string as the keyword value.  default is TRUE.\n",
       "\n",
       "     ...: other arguments.\n",
       "\n",
       "_\bD_\be_\bt_\ba_\bi_\bl_\bs:\n",
       "\n",
       "     The function ‘isFCSfile’ determines whether its arguments are\n",
       "     valid FCS files.\n",
       "\n",
       "     The function ‘read.FCS’ works with the output of the FACS machine\n",
       "     software from a number of vendors (FCS 2.0, FCS 3.0 and List Mode\n",
       "     Data LMD). However, the FCS 3.0 standard includes some options\n",
       "     that are not yet implemented in this function. If you need\n",
       "     extensions, please let me know. The output of the function is an\n",
       "     object of class ‘flowFrame’.\n",
       "\n",
       "     For specifications of FCS 3.0 see <URL: http://www.isac-net.org>\n",
       "     and the file <URL: ../doc/fcs3.html> in the ‘doc’ directory of the\n",
       "     package.\n",
       "\n",
       "     The ‘which.lines’ arguments allow you to read a subset of the\n",
       "     record as you might not want to read the thousands of events\n",
       "     recorded in the FCS file.  It is mainly used when there is not\n",
       "     enough memory to read one single FCS (which probably will not\n",
       "     happen).  It will probably take more time than reading the entire\n",
       "     FCS (due to the multiple disk IO).\n",
       "\n",
       "_\bV_\ba_\bl_\bu_\be:\n",
       "\n",
       "     ‘isFCSfile’ returns a logical vector.\n",
       "\n",
       "     ‘read.FCS’ returns an object of class ‘flowFrame’ that contains\n",
       "     the data in the ‘exprs’ slot, the parameters monitored in the\n",
       "     ‘parameters’ slot and the keywords and value saved in the header\n",
       "     of the FCS file.\n",
       "\n",
       "_\bA_\bu_\bt_\bh_\bo_\br(_\bs):\n",
       "\n",
       "     F. Hahne, N.Le Meur\n",
       "\n",
       "_\bS_\be_\be _\bA_\bl_\bs_\bo:\n",
       "\n",
       "     ‘read.flowSet’\n",
       "\n",
       "_\bE_\bx_\ba_\bm_\bp_\bl_\be_\bs:\n",
       "\n",
       "     ## a sample file\n",
       "     fcsFile <- system.file(\"extdata\", \"0877408774.B08\", package=\"flowCore\")\n",
       "     \n",
       "     ## read file and linearize values\n",
       "     samp <-  read.FCS(fcsFile, transformation=\"linearize\")\n",
       "     exprs(samp[1:3,])\n",
       "     description(samp)[3:6]\n",
       "     class(samp)\n",
       "     \n",
       "     ## Only read in lines 2 to 5\n",
       "     subset <- read.FCS(fcsFile, which.lines=2:5, transformation=\"linearize\")\n",
       "     exprs(subset)\n",
       "     \n",
       "     ## Read in a random sample of 100 lines\n",
       "     subset <- read.FCS(fcsFile, which.lines=100, transformation=\"linearize\")\n",
       "     nrow(subset)\n",
       "     "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "help(package=\"flowCore\")\n",
    "?read.FCS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "to obtain an overview of help on the `flowCore` package, and the `read.FCS` function, and"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "starting httpd help server ... done\n"
     ]
    }
   ],
   "source": [
    "browseVignettes(package=\"flowCore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "to view vignettes (providing a more comprehensive introduction to package functionality) in the `flowCore` package. Use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "If the browser launched by '/usr/bin/firefox' is already running, it is\n",
      "    *not* restarted, and you must switch to its window.\n",
      "Otherwise, be patient ...\n"
     ]
    }
   ],
   "source": [
    "help.start()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "to open a web page containing comprehensive help resources.\n",
    "\n",
    "<p class=\"back_to_top\">\n",
    "\\[ <a href=\"#top\">Back to top</a> \\]\n",
    "</p>\n",
    "<h2 id=\"diverse-assays-resources\">\n",
    "Diverse Assays Resources\n",
    "</h2>\n",
    "The following provide a brief overview of packages useful for analysis of high-throughput assays. More comprehensive workflows can be found in documentation (available from [package descriptions](/packages/release/bioc/)) and in Bioconductor [publications](/help/publications/).\n",
    "\n",
    "### Flow Cytometry\n",
    "\n",
    "These packages use standard FCS files, including infrastructure, utilities, visualization and semi-autogating methods for the analysis of flow cytometry data.\n",
    "\n",
    "[flowCore](/packages/release/bioc/html/flowCore.html), [flowViz](/packages/release/bioc/html/flowViz.html), [flowQ](/packages/release/bioc/html/flowQ.html), [flowStats](/packages/release/bioc/html/flowStats.html), [flowUtils](/packages/release/bioc/html/flowUtils.html), [flowFP](/packages/release/bioc/html/flowFP.html), [flowTrans](/packages/release/bioc/html/flowTrans.html),\n",
    "\n",
    "Algorithms for clustering flow cytometry data are found in these packages:\n",
    "\n",
    "[flowClust](/packages/release/bioc/html/flowClust.html), [flowMeans](/packages/release/bioc/html/flowMeans.html), [flowMerge](/packages/release/bioc/html/flowMerge.html), [SamSPECTRAL](/packages/release/bioc/html/SamSPECTRAL.html)\n",
    "\n",
    "A typical workflow using the packages `flowCore`, `flowViz`, `flowQ` and `flowStats` is described in detail in [flowWorkFlow.pdf](flowWorkFlow.pdf). The data files used in the workflow can be downloaded from [here](dataFiles.tar).\n",
    "\n",
    "### Cell-based Assays\n",
    "\n",
    "These packages provide data structures and algorithms for cell-based high-throughput screens (HTS).\n",
    "\n",
    "[cellHTS2](/packages/release/bioc/html/cellHTS2.html), [RNAither](/packages/release/bioc/html/RNAither.html)\n",
    "\n",
    "This package supports the xCELLigence system which contains a series of real-time cell analyzer (RTCA).\n",
    "\n",
    "[RTCA](/packages/release/bioc/html/RTCA.html)\n",
    "\n",
    "### High-throughput qPCR Assays\n",
    "\n",
    "These package provide algorithm for the analysis of cycle threshold (Ct) from quantitative real-time PCR data.\n",
    "\n",
    "[HTqPCR](/packages/release/bioc/html/HTqPCR.html), [ddCt](/packages/release/bioc/html/ddCt.html), [qpcrNorm](/packages/release/bioc/html/qpcrNorm.html)\n",
    "\n",
    "### Mass Spectrometry and Proteomics data\n",
    "\n",
    "These packages provide framework for processing, visualization, and statistical analysis of mass spectral and proteomics data.\n",
    "\n",
    "[clippda](/packages/release/bioc/html/clippda.html), [MassArray](/packages/release/bioc/html/MassArray.html), [MassSpecWavelet](/packages/release/bioc/html/MassSpecWavelet.html), [PROcess](/packages/release/bioc/html/PROcess.html), [flagme](/packages/release/bioc/html/flagme.html), [xcms](/packages/release/bioc/html/xcms.html)\n",
    "\n",
    "### Imaging Based Assays\n",
    "\n",
    "These packages provide infrastructure for image-based phenotyping and automation of other image-related tasks:\n",
    "\n",
    "[EBImage](/packages/release/bioc/html/EBImage.html)\n",
    "\n",
    "<p class=\"back_to_top\">\n",
    "\\[ <a href=\"#top\">Back to top</a> \\]\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "R version 3.2.2 (2015-08-14)\n",
       "Platform: x86_64-pc-linux-gnu (64-bit)\n",
       "Running under: Ubuntu 14.04.3 LTS\n",
       "\n",
       "locale:\n",
       " [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C              \n",
       " [3] LC_TIME=en_US.UTF-8        LC_COLLATE=en_US.UTF-8    \n",
       " [5] LC_MONETARY=de_DE.UTF-8    LC_MESSAGES=en_US.UTF-8   \n",
       " [7] LC_PAPER=de_DE.UTF-8       LC_NAME=C                 \n",
       " [9] LC_ADDRESS=C               LC_TELEPHONE=C            \n",
       "[11] LC_MEASUREMENT=de_DE.UTF-8 LC_IDENTIFICATION=C       \n",
       "\n",
       "attached base packages:\n",
       "[1] splines   stats     graphics  grDevices utils     datasets  methods  \n",
       "[8] base     \n",
       "\n",
       "other attached packages:\n",
       " [1] BiocInstaller_1.20.1      flowStats_3.28.1         \n",
       " [3] flowWorkspace_3.16.5      gridExtra_2.0.0          \n",
       " [5] ncdfFlow_2.16.0           BH_1.58.0-1              \n",
       " [7] RcppArmadillo_0.6.300.2.2 flowViz_1.34.0           \n",
       " [9] lattice_0.20-33           cluster_2.0.3            \n",
       "[11] mvoutlier_2.0.6           sgeostat_1.0-26          \n",
       "[13] fda_2.4.4                 Matrix_1.2-3             \n",
       "[15] flowCore_1.36.3          \n",
       "\n",
       "loaded via a namespace (and not attached):\n",
       " [1] rgl_0.95.1429         Rcpp_0.12.2           mvtnorm_1.0-3        \n",
       " [4] corpcor_1.6.8         assertthat_0.1        digest_0.6.8         \n",
       " [7] IRdisplay_0.3         R6_2.1.1              plyr_1.8.3           \n",
       "[10] chron_2.3-47          repr_0.4              stats4_3.2.2         \n",
       "[13] pcaPP_1.9-60          evaluate_0.8          ggplot2_1.0.1        \n",
       "[16] zlibbioc_1.16.0       misc3d_0.8-4          uuid_0.1-2           \n",
       "[19] data.table_1.9.6      Rgraphviz_2.14.0      hexbin_1.27.1        \n",
       "[22] robCompositions_1.9.1 RUnit_0.4.31          proto_0.3-10         \n",
       "[25] stringr_1.0.0         sROC_0.1-2            munsell_0.4.2        \n",
       "[28] BiocGenerics_0.16.1   base64enc_0.1-3       rzmq_0.7.7           \n",
       "[31] IDPmisc_1.1.17        multicool_0.1-9       codetools_0.2-14     \n",
       "[34] XML_3.98-1.3          reshape_0.8.5         rrcov_1.3-8          \n",
       "[37] dplyr_0.4.3           MASS_7.3-45           grid_3.2.2           \n",
       "[40] RBGL_1.46.0           jsonlite_0.9.19       GGally_0.5.0         \n",
       "[43] gtable_0.1.2          DBI_0.3.1             magrittr_1.5         \n",
       "[46] scales_0.3.0          graph_1.48.0          KernSmooth_2.23-15   \n",
       "[49] stringi_1.0-1         reshape2_1.4.1        latticeExtra_0.6-26  \n",
       "[52] robustbase_0.92-5     flowUtils_1.34.0      pls_2.5-0            \n",
       "[55] IRkernel_0.5          RColorBrewer_1.1-2    tools_3.2.2          \n",
       "[58] Biobase_2.30.0        DEoptimR_1.0-4        ks_1.10.0            \n",
       "[61] parallel_3.2.2        colorspace_1.2-6     "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sessionInfo()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p class=\"back_to_top\">\n",
    "\\[ <a href=\"#top\">Back to top</a> \\]\n",
    "</p>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}